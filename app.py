import streamlit as st
import json
from datetime import datetime
from openai import OpenAI
import os
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (API í‚¤ê°€ ì—†ìœ¼ë©´ Noneìœ¼ë¡œ ì„¤ì •)
api_key = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=api_key) if api_key else None

# í˜ì´ì§€ ì„¤ì •ì„ ì™€ì´ë“œ ëª¨ë“œë¡œ ë³€ê²½í•˜ê³  í•œê¸€ í°íŠ¸ ì§€ì›
st.set_page_config(layout="wide", page_title="AB Test Tool", page_icon="ğŸ¤–")
st.markdown("""
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+KR&display=swap');
        html, body, [class*="css"] {
            font-family: 'Noto Sans KR', sans-serif;
        }
    </style>
    """, unsafe_allow_html=True)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'test_results' not in st.session_state:
    st.session_state.test_results = []
if 'last_run_results' not in st.session_state:
    st.session_state.last_run_results = None
if 'current_settings' not in st.session_state:
    st.session_state.current_settings = {
        'model_a': 'gpt-3.5-turbo',
        'model_b': 'gpt-3.5-turbo',
        'temperature_a': 0.7,
        'temperature_b': 0.7,
        'max_tokens_a': 256,
        'max_tokens_b': 256,
        'top_p_a': 1.0,
        'top_p_b': 1.0,
        'presence_penalty_a': 0.0,
        'presence_penalty_b': 0.0,
        'frequency_penalty_a': 0.0,
        'frequency_penalty_b': 0.0,
        'system_prompt': 'ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AIì…ë‹ˆë‹¤.',
    }
if 'save_results' not in st.session_state:
    st.session_state.save_results = False

# ëª¨ë¸ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
def generate_model_response(model, system_prompt, user_input, temperature, max_tokens, top_p, presence_penalty, frequency_penalty):
    if model == "ClovaX":
        return f"ClovaXì˜ ì‘ë‹µ: ì´ê²ƒì€ í…ŒìŠ¤íŠ¸ ì‘ë‹µì…ë‹ˆë‹¤. í•œê¸€ í…ŒìŠ¤íŠ¸: ì•ˆë…•í•˜ì„¸ìš”."
    elif client is None:
        return "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”."
    else:
        try:
            completion = client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_input}
                ],
                temperature=temperature,
                max_tokens=max_tokens,
                top_p=top_p,
                presence_penalty=presence_penalty,
                frequency_penalty=frequency_penalty
            )
            return completion.choices[0].message.content
        except Exception as e:
            return f"Error: {str(e)}"

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ ë° í…ŒìŠ¤íŠ¸ ì‹¤í–‰ í•¨ìˆ˜
def process_user_input_and_run_test():
    st.session_state.processed_input = st.session_state.user_input
    st.session_state.run_test = True

# ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜
def save_results_to_json(results):
    if results:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"test_results_{timestamp}.json"
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        st.success(f"ê²°ê³¼ê°€ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        st.warning("ì €ì¥í•  í…ŒìŠ¤íŠ¸ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

# ì œëª© ë° ì„¤ëª…
st.title("Chatbot Arena")
st.write("ì±—ë´‡ ì•„ë ˆë‚˜ ë°©ì‹ìœ¼ë¡œ ë‘ ê°œì˜ LLMì„ ë¹„êµí•´ë³´ì„¸ìš”.")

# ë©”ì¸ ë ˆì´ì•„ì›ƒ
col1, col2 = st.columns([3, 1])

# ê²°ê³¼ í‘œì‹œ ë¶€ë¶„ (ì™¼ìª½ ì¹¼ëŸ¼)
with col1:
    st.subheader("ëª¨ë¸ ì‘ë‹µ ë¹„êµ")
    
    # í…ŒìŠ¤íŠ¸ íšŸìˆ˜ ì„¤ì •
    num_tests = st.number_input("í…ŒìŠ¤íŠ¸ íšŸìˆ˜", min_value=1, max_value=30, value=1, step=1)
    
    # ì €ì¥ ì˜µì…˜
    save_option = st.checkbox("ê²°ê³¼ ì €ì¥", value=False)
    
    if 'processed_input' in st.session_state and st.session_state.processed_input:
        st.write(f"**ì‚¬ìš©ì:** {st.session_state.processed_input}")
        
        if st.session_state.get('run_test', False):
            st.session_state.last_run_results = []
            for test_num in range(num_tests):
                st.write(f"**í…ŒìŠ¤íŠ¸ #{test_num + 1}**")
                subcol1, subcol2 = st.columns(2)
                test_result = {
                    "test_number": test_num + 1,
                    "user_input": st.session_state.processed_input,
                    "system_prompt": st.session_state.current_settings['system_prompt'],
                    "models": {}
                }
                for col, model_key, model_name in [(subcol1, 'model_a', 'ëª¨ë¸ A'), (subcol2, 'model_b', 'ëª¨ë¸ B')]:
                    with col:
                        response = generate_model_response(
                            st.session_state.current_settings[model_key],
                            st.session_state.current_settings['system_prompt'],
                            st.session_state.processed_input,
                            st.session_state.current_settings[f'temperature_{model_key[-1]}'],
                            st.session_state.current_settings[f'max_tokens_{model_key[-1]}'],
                            st.session_state.current_settings[f'top_p_{model_key[-1]}'],
                            st.session_state.current_settings[f'presence_penalty_{model_key[-1]}'],
                            st.session_state.current_settings[f'frequency_penalty_{model_key[-1]}']
                        )
                        st.markdown(f"""
                        <div style="border:1px solid #ddd; padding:10px; border-radius:5px;">
                            <h4 style="margin-top:0;">{st.session_state.current_settings[model_key]}</h4>
                            <p>{response}</p>
                        </div>
                        """, unsafe_allow_html=True)
                        test_result["models"][model_name] = {
                            "name": st.session_state.current_settings[model_key],
                            "response": response,
                            "settings": {
                                "temperature": st.session_state.current_settings[f'temperature_{model_key[-1]}'],
                                "max_tokens": st.session_state.current_settings[f'max_tokens_{model_key[-1]}'],
                                "top_p": st.session_state.current_settings[f'top_p_{model_key[-1]}'],
                                "presence_penalty": st.session_state.current_settings[f'presence_penalty_{model_key[-1]}'],
                                "frequency_penalty": st.session_state.current_settings[f'frequency_penalty_{model_key[-1]}']
                            }
                        }
                st.write("---")
                st.session_state.last_run_results.append(test_result)
            st.session_state.run_test = False
            
            # ì €ì¥ ì˜µì…˜ì´ ì„ íƒë˜ì—ˆì„ ë•Œë§Œ ê²°ê³¼ ì €ì¥
            if save_option:
                save_results_to_json(st.session_state.last_run_results)
        
        if st.session_state.last_run_results:
            # ì´ì „ ì‹¤í–‰ ê²°ê³¼ í‘œì‹œ
            for test_result in st.session_state.last_run_results:
                st.write(f"**í…ŒìŠ¤íŠ¸ #{test_result['test_number']}**")
                subcol1, subcol2 = st.columns(2)
                for col, model_name in [(subcol1, 'ëª¨ë¸ A'), (subcol2, 'ëª¨ë¸ B')]:
                    with col:
                        response = test_result["models"][model_name]["response"]
                        st.markdown(f"""
                        <div style="border:1px solid #ddd; padding:10px; border-radius:5px;">
                            <h4 style="margin-top:0;">{test_result["models"][model_name]["name"]}</h4>
                            <p>{response}</p>
                        </div>
                        """, unsafe_allow_html=True)
                st.write("---")
    else:
        st.write("ì•„ì§ ì‚¬ìš©ì ì…ë ¥ì´ ì—†ìŠµë‹ˆë‹¤.")

# ì„¤ì • ë° ì…ë ¥ ë¶€ë¶„ (ì˜¤ë¥¸ìª½ ì¹¼ëŸ¼)
with col2:
    st.subheader("ì„¤ì • ë° ì…ë ¥")
    
    # API í‚¤ ìƒíƒœ í‘œì‹œ
    if api_key:
        st.success("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        st.warning("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
    
    tab1, tab2 = st.tabs(["ì±„íŒ… ì¸í„°í˜ì´ìŠ¤", "ëª¨ë¸ ì„¤ì •"])
    
    # ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ íƒ­
    with tab1:
        st.session_state.current_settings['system_prompt'] = st.text_area("ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸", value=st.session_state.current_settings['system_prompt'])
        user_input = st.text_input("ì‚¬ìš©ì ì…ë ¥", key="user_input")

        # ëŒ€í™” ì²˜ë¦¬
        if st.button("ì „ì†¡"):
            if st.session_state.user_input:
                process_user_input_and_run_test()
            else:
                st.write("ì‚¬ìš©ì ì…ë ¥ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    # ëª¨ë¸ ì„¤ì • íƒ­
    with tab2:
        st.subheader("ëª¨ë¸ A ì„¤ì •")
        st.session_state.current_settings['model_a'] = st.selectbox("ëª¨ë¸ A ì„ íƒ", ("gpt-3.5-turbo", "gpt-4", "ClovaX"), key="model_a")
        st.session_state.current_settings['temperature_a'] = st.slider("Temperature (ëª¨ë¸ A)", 0.0, 1.0, st.session_state.current_settings['temperature_a'], key="temperature_a")
        st.session_state.current_settings['max_tokens_a'] = st.slider("Max Tokens (ëª¨ë¸ A)", 50, 1024, st.session_state.current_settings['max_tokens_a'], key="max_tokens_a")
        st.session_state.current_settings['top_p_a'] = st.slider("Top P (ëª¨ë¸ A)", 0.0, 1.0, st.session_state.current_settings['top_p_a'], key="top_p_a")
        st.session_state.current_settings['presence_penalty_a'] = st.slider("Presence Penalty (ëª¨ë¸ A)", -2.0, 2.0, st.session_state.current_settings['presence_penalty_a'], key="presence_penalty_a")
        st.session_state.current_settings['frequency_penalty_a'] = st.slider("Frequency Penalty (ëª¨ë¸ A)", -2.0, 2.0, st.session_state.current_settings['frequency_penalty_a'], key="frequency_penalty_a")

        st.subheader("ëª¨ë¸ B ì„¤ì •")
        st.session_state.current_settings['model_b'] = st.selectbox("ëª¨ë¸ B ì„ íƒ", ("gpt-3.5-turbo", "gpt-4", "ClovaX"), key="model_b")
        st.session_state.current_settings['temperature_b'] = st.slider("Temperature (ëª¨ë¸ B)", 0.0, 1.0, st.session_state.current_settings['temperature_b'], key="temperature_b")
        st.session_state.current_settings['max_tokens_b'] = st.slider("Max Tokens (ëª¨ë¸ B)", 50, 1024, st.session_state.current_settings['max_tokens_b'], key="max_tokens_b")
        st.session_state.current_settings['top_p_b'] = st.slider("Top P (ëª¨ë¸ B)", 0.0, 1.0, st.session_state.current_settings['top_p_b'], key="top_p_b")
        st.session_state.current_settings['presence_penalty_b'] = st.slider("Presence Penalty (ëª¨ë¸ B)", -2.0, 2.0, st.session_state.current_settings['presence_penalty_b'], key="presence_penalty_b")
        st.session_state.current_settings['frequency_penalty_b'] = st.slider("Frequency Penalty (ëª¨ë¸ B)", -2.0, 2.0, st.session_state.current_settings['frequency_penalty_b'], key="frequency_penalty_b")